# Hi, I'm Rohit Ashva ğŸ‘‹

## ğŸš€ Data Engineer | Freelancer | Python & SQL Expert | Web Scraping Specialist

Welcome to my GitHub! I'm a **Data Engineer** with production-level experience in **Python, SQL, and cloud platforms like Microsoft Azure and AWS**. I specialize in **building robust, scalable, and automated data pipelines** for business intelligence and analytics.

---

## ğŸ› ï¸ Skills & Technologies

- ğŸ”¹ **Programming:** Python ğŸ, SQL ğŸ—„ï¸, PySpark âš¡  
- ğŸ—ƒï¸ **Databases:** PostgreSQL ğŸ˜, MySQL ğŸ¦, SQL Server ğŸ¢  
- â˜ï¸ **Cloud Platforms:**  
  - **Microsoft Azure:** Data Factory ğŸ­, Data Lake ğŸŒŠ, Databricks ğŸ”¥  
  - **AWS:** S3 ğŸª£, EC2 ğŸ–¥ï¸  
- ğŸ”„ **Workflow Orchestration:** Apache Airflow ğŸŒ¬ï¸  
- ğŸ“Š **Data Analysis & Processing:** Pandas ğŸ¼, NumPy ğŸ”¢, ETL/ELT âš™ï¸  
- ğŸ¤– **Automation & Web Scraping:** Selenium ğŸ•·ï¸, BeautifulSoup ğŸœ, Requests ğŸ”—  

---

## ğŸ’¼ Services I Offer

- ğŸš€ **Scalable Data Pipelines** â€“ Production-grade ETL workflows with monitoring and logging  
- âš™ï¸ **Cloud Integration** â€“ Deploy and manage pipelines on **Azure Data Factory** and **AWS EC2/S3**  
- ğŸ›¡ï¸ **Reliable Automation** â€“ Error handling, retry logic, and alerts built into data workflows  
- ğŸ”„ **Database Management** â€“ Performance tuning and advanced querying in **PostgreSQL & MySQL**  
- ğŸ”— **API & Web Scraping** â€“ Structured extraction from public APIs and complex, JS-heavy websites  
- ğŸ“Š **Data Engineering Best Practices** â€“ Code modularization, version control (Git), and CI/CD readiness  

---

## ğŸ“‚ Featured Projects

### ğŸ§© Web Scraping & Government Data Pipelines

- **ğŸ“„ Legislative Data Pipelines for U.S. States (2024â€“2025)**  
  Production-ready scrapers for over **15 U.S. states**, handling:  
  âœ”ï¸ Dynamic content rendering (Selenium + undetected_chromedriver)  
  âœ”ï¸ PDF & Excel generation with organized file structure  
  âœ”ï¸ Modular architecture for state-specific rules  
  âœ”ï¸ Scheduled deployments on AWS EC2 with logging and retry logic  
  âœ”ï¸ Output stored on AWS S3 or local file systems for downstream use

- **ğŸ“‚ [Amazon Product ETL Pipeline â€“ Apache Airflow](https://github.com/rohit-ashva900/apache_airflow_ETL_amazon)**  
  ETL pipeline using Apache Airflow with PostgreSQL backend and email alerts on DAG failure.

- **ğŸ“ˆ [Walmart Sales Data Analysis](https://github.com/rohit-ashva900/walmart_Analysis)**  
  Data cleaning, transformation, SQL querying, and visualization â€“ all aligned with BI practices.

- **ğŸ“Š E-commerce Market Scraper (Freelance)**  
  Full automation using retry-capable scrapers, proxy rotation, and structured CSV/JSON output.

---

## ğŸ”§ Production-Level Engineering Stack

- **Logging & Monitoring:** Python `logging`, Airflow monitoring, email alerts  
- **Error Handling:** Try/except blocks with fallback logic, status checks, and recovery flows  
- **Deployment:** Scripts deployed via **cron**, **Airflow**, and **EC2** for scheduled automation  
- **Storage & Delivery:** PostgreSQL for relational storage, S3 for file archiving and pipeline output  
- **Version Control:** All production code maintained in GitHub repositories  

---

## ğŸ“ Contact Me

ğŸ“§ **Email:** rohit.ashva900@gmail.com  
ğŸ”— **LinkedIn:** [linkedin.com/in/rohit-ashva](https://www.linkedin.com/in/rohit-ashva)

Letâ€™s build clean, scalable, and production-ready data systems â€” built to perform. ğŸš€
